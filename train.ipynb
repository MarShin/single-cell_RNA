{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "[[  0 121 102 ...,   0   0  82]\n",
      " [  0 113  44 ..., 152   0 165]\n",
      " [  0 221   0 ...,  25   0 161]\n",
      " ..., \n",
      " [  0 301  40 ..., 481   0  55]\n",
      " [  0 101 118 ..., 402   0 120]\n",
      " [  0  58   0 ..., 152   0  92]]\n",
      "(115, 15801)\n",
      "(29, 15801)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import data_handler as dh\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x_train, x_test = dh.load_data()\n",
    "\n",
    "# x_train = x_train.astype('float32') / 255.\n",
    "# x_test = x_test.astype('float32') / 255.\n",
    "# x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "# x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "\n",
    "\n",
    "print type(x_train)\n",
    "print x_test\n",
    "print x_train.shape\n",
    "print x_test.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the size of our encoded representations\n",
    "encoding_dim = 10000  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(15801,))\n",
    "\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
    "encoded = Dense(5000, activation='relu')(encoded)\n",
    "\n",
    "decoded = Dense(10000, activation='relu')(encoded)\n",
    "decoded = Dense(15801, activation='sigmoid')(decoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)\n",
    "\n",
    "encoder = Model(input_img, encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "\n",
    "\n",
    "# autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "autoencoder.compile(optimizer='rmsprop', loss='mse')\n",
    "# autoencoder.save('denoisedAE.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoencoder.fit(x_train, x_train,\n",
    "#                 epochs=10,\n",
    "#                 batch_size=256,\n",
    "#                 shuffle=True,\n",
    "#                 validation_data=(x_test, x_test))\n",
    "\n",
    "\n",
    "# # encode and decode some digits\n",
    "# # note that we take them from the *test* set\n",
    "# encoded_imgs = encoder.predict(x_test)\n",
    "# decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "# def plot():\n",
    "#     pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot():\n",
    "\n",
    "    plt.imshow(x_train, cmap='hot', interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAAlCAYAAABMDyIGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncv4P3VrwAZIe+oQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110fc3690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115, 15801)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
